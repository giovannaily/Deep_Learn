{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/giovannaily/Deep_Learn/blob/main/Fresh_and_rotten_fruits.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Universidade Federal de Pernambuco - UFPE \\\n",
        "Centro de Informática - CIn \\\n",
        "Ciência da computação - Pós graduação \\\n",
        "Deep Learn 2024.1 \\\n",
        "Student: Giovanna Ily Farias Ramalho"
      ],
      "metadata": {
        "id": "seHspoxsbBbN"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQdR67lmSc9R"
      },
      "source": [
        "# Fresh and rotten fruits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yik2aH5pcW6"
      },
      "source": [
        "In this notebook, I am training a model to recognize fresh and rotten fruits. The dataset comes from [Kaggle](https://www.kaggle.com/sriramr/fruits-fresh-and-rotten-for-classification). There are 6 categories of fruits: fresh apples, fresh oranges, fresh bananas, rotten apples, rotten oranges, and rotten bananas. My model require an output layer of 6 neurons."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjOqCO-iLso7"
      },
      "source": [
        "Load Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h50KPvwoElco",
        "outputId": "e3716c24-70f7-4fcc-dff8-552f8143f422"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive', force_remount = True)\n",
        "os.chdir('/content/drive/MyDrive/dataset/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8gLrnqmL0Hh"
      },
      "source": [
        "Import pre-trainning model from image.net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NsFN-DHlLSOm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57a078a9-4fa3-4fa2-b72e-c3711f014acd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 4s 0us/step\n"
          ]
        }
      ],
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "# Carregando o modelo VGG16 pré-treinado com pesos do ImageNet\n",
        "# e sem as camadas totalmente conectadas no topo do modelo.\n",
        "base_model = keras.applications.VGG16(\n",
        "    weights='imagenet',  # Utiliza os pesos treinados no ImageNet\n",
        "    input_shape=(224, 224, 3),  # Define a forma de entrada conforme requerido\n",
        "    include_top=False)  # Não inclui as camadas superiores (fully-connected layers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VoSJWCg4MNpT"
      },
      "source": [
        "Freeze the base model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OoJ0jj5yMTz0"
      },
      "outputs": [],
      "source": [
        "# Freeze base model\n",
        "base_model.trainable = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_JjP2Up9s9N"
      },
      "source": [
        "Add layers to model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d1GfrbwEpcXF"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Flatten, Dense\n",
        "\n",
        "# 1. Criar os inputs com a forma correta\n",
        "inputs = Input(shape=(224, 224, 3))\n",
        "\n",
        "# 2. Passar inputs para o modelo base, definindo training como False para usar as camadas em modo de inferência\n",
        "x = base_model(inputs, training=False)\n",
        "\n",
        "# 3. Adicionar uma camada de pooling para reduzir a dimensionalidade ou uma camada Flatten\n",
        "# Aqui vamos usar GlobalAveragePooling2D, mas você pode usar Flatten() se preferir\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "# 4. Adicionar a camada densa final para classificação\n",
        "# Suponha que temos 10 classes para este exemplo\n",
        "outputs = Dense(10, activation='softmax')(x)\n",
        "\n",
        "# 5. Combinar inputs e outputs para criar o modelo\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9IDpffLnpcXG",
        "outputId": "4ec15bba-638e-471e-cd97-6b29765e2908"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " vgg16 (Functional)          (None, 7, 7, 512)         14714688  \n",
            "                                                                 \n",
            " global_average_pooling2d (  (None, 512)               0         \n",
            " GlobalAveragePooling2D)                                         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14719818 (56.15 MB)\n",
            "Trainable params: 5130 (20.04 KB)\n",
            "Non-trainable params: 14714688 (56.13 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGOO8BgwpcXH"
      },
      "source": [
        "## Compile Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QXWxsNoE-fTg"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    loss='sparse_categorical_crossentropy',  # Para labels em formato de inteiros\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bg1DPxaepcXI"
      },
      "source": [
        "## Augment the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8pIXovQs-obc"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Data augmentation para o conjunto de treinamento\n",
        "datagen_train = ImageDataGenerator(\n",
        "    rotation_range=40,       # Rotação de até 40 graus\n",
        "    width_shift_range=0.2,   # Deslocamento horizontal até 20%\n",
        "    height_shift_range=0.2,  # Deslocamento vertical até 20%\n",
        "    shear_range=0.2,         # Cisalhamento até 20%\n",
        "    zoom_range=0.2,          # Zoom de até 20%\n",
        "    horizontal_flip=True,    # Permitir espelhamento horizontal\n",
        "    fill_mode='nearest',     # Modo de preenchimento para novos pixels\n",
        "    rescale=1./255           # Escala os valores de pixel para o intervalo [0,1]\n",
        ")\n",
        "\n",
        "# Apenas reescala para o conjunto de validação\n",
        "datagen_valid = ImageDataGenerator(\n",
        "    rescale=1./255           # Escala os valores de pixel para o intervalo [0,1]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhnrPCMRpcXK"
      },
      "source": [
        "## Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OiL5GXc_Md8",
        "outputId": "19d8b31a-b24a-4ecb-c34c-4cee507217a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3998 images belonging to 6 classes.\n",
            "Found 3998 images belonging to 6 classes.\n"
          ]
        }
      ],
      "source": [
        "# load and iterate training dataset\n",
        "train_it = datagen_train.flow_from_directory(\n",
        "    '/content/drive/MyDrive/dataset/train',  # Caminho para o diretório de treinamento\n",
        "    target_size=(224, 224),                           # As imagens são redimensionadas para 224x224\n",
        "    color_mode=\"rgb\",                                 # Usar imagens em cores\n",
        "    class_mode=\"categorical\",                         # As labels serão one-hot encoded\n",
        "    batch_size=32                                     # Processa 32 imagens por lote\n",
        ")\n",
        "\n",
        "# load and iterate \"validation\" dataset, now using a general directory that includes multiple folders\n",
        "valid_it = datagen_valid.flow_from_directory(\n",
        "    '/content/drive/MyDrive/dataset/train',  # Caminho ajustado para o diretório que contém todas as subpastas\n",
        "    target_size=(224, 224),                               # As imagens são redimensionadas para 224x224\n",
        "    color_mode=\"rgb\",                                     # Usar imagens em cores\n",
        "    class_mode=\"categorical\",                             # As labels serão one-hot encoded\n",
        "    batch_size=32                                         # Processa 32 imagens por lote\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFHTEeKhKLZX",
        "outputId": "da5075ae-a855-4876-c25f-a12c70b713b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " vgg16 (Functional)          (None, 7, 7, 512)         14714688  \n",
            "                                                                 \n",
            " global_average_pooling2d_1  (None, 512)               0         \n",
            "  (GlobalAveragePooling2D)                                       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 6)                 3078      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14717766 (56.14 MB)\n",
            "Trainable params: 3078 (12.02 KB)\n",
            "Non-trainable params: 14714688 (56.13 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense\n",
        "from tensorflow import keras\n",
        "\n",
        "# Suponho que você já tenha base_model configurado e não treinável\n",
        "inputs = Input(shape=(224, 224, 3))\n",
        "x = base_model(inputs, training=False)\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "outputs = Dense(6, activation='softmax')(x)  # Corrigindo o número de neurônios para 6\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "# Recompile o modelo após ajustar a camada de saída\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7PmaKJEKNyP",
        "outputId": "f84e2ac6-1a31-41f2-f1ec-e87956829c19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3998 images belonging to 6 classes.\n",
            "Found 3998 images belonging to 6 classes.\n"
          ]
        }
      ],
      "source": [
        "# Verificação de class_mode e ajustes do ImageDataGenerator\n",
        "datagen_train = ImageDataGenerator(\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    rescale=1./255\n",
        ")\n",
        "train_it = datagen_train.flow_from_directory(\n",
        "    '/content/drive/MyDrive/dataset/train',\n",
        "    target_size=(224, 224),\n",
        "    color_mode=\"rgb\",\n",
        "    class_mode=\"categorical\",\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "datagen_valid = ImageDataGenerator(rescale=1./255)\n",
        "valid_it = datagen_valid.flow_from_directory(\n",
        "    '/content/drive/MyDrive/dataset/train',\n",
        "    target_size=(224, 224),\n",
        "    color_mode=\"rgb\",\n",
        "    class_mode=\"categorical\",\n",
        "    batch_size=32\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkBc3yrJpcXL"
      },
      "source": [
        "## Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0kS89qLB2B0",
        "outputId": "97ffb32e-5bd1-4531-f4c1-c50f231bf45b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "124/124 [==============================] - 1713s 14s/step - loss: 0.8957 - accuracy: 0.7254 - val_loss: 0.6132 - val_accuracy: 0.8019\n",
            "Epoch 2/10\n",
            "124/124 [==============================] - 122s 982ms/step - loss: 0.5863 - accuracy: 0.8174 - val_loss: 0.4414 - val_accuracy: 0.8198\n",
            "Epoch 3/10\n",
            "124/124 [==============================] - 113s 916ms/step - loss: 0.4572 - accuracy: 0.8704 - val_loss: 0.3463 - val_accuracy: 0.8642\n",
            "Epoch 4/10\n",
            "124/124 [==============================] - 114s 920ms/step - loss: 0.3794 - accuracy: 0.9034 - val_loss: 0.2931 - val_accuracy: 0.8851\n",
            "Epoch 5/10\n",
            "124/124 [==============================] - 121s 978ms/step - loss: 0.3320 - accuracy: 0.9181 - val_loss: 0.2437 - val_accuracy: 0.9332\n",
            "Epoch 6/10\n",
            "124/124 [==============================] - 121s 977ms/step - loss: 0.2966 - accuracy: 0.9266 - val_loss: 0.2328 - val_accuracy: 0.9050\n",
            "Epoch 7/10\n",
            "124/124 [==============================] - 122s 988ms/step - loss: 0.2668 - accuracy: 0.9355 - val_loss: 0.1968 - val_accuracy: 0.9483\n",
            "Epoch 8/10\n",
            "124/124 [==============================] - 113s 909ms/step - loss: 0.2449 - accuracy: 0.9473 - val_loss: 0.1880 - val_accuracy: 0.9410\n",
            "Epoch 9/10\n",
            "124/124 [==============================] - 122s 983ms/step - loss: 0.2297 - accuracy: 0.9443 - val_loss: 0.1691 - val_accuracy: 0.9511\n",
            "Epoch 10/10\n",
            "124/124 [==============================] - 113s 910ms/step - loss: 0.2096 - accuracy: 0.9564 - val_loss: 0.1713 - val_accuracy: 0.9367\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c2dfc5f74f0>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "model.fit(\n",
        "    train_it,  # Gerador de dados de treinamento\n",
        "    validation_data=valid_it,  # Gerador de dados de validação\n",
        "    steps_per_epoch=train_it.samples // train_it.batch_size,  # Usando divisão inteira para garantir um número inteiro\n",
        "    validation_steps=valid_it.samples // valid_it.batch_size,  # Usando divisão inteira para garantir um número inteiro\n",
        "    epochs=10  # Definindo um número de épocas para treinamento\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTTtclVtpcXO"
      },
      "source": [
        "## Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h8x_h2_ZpcXO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d50b9d0c-6915-41f2-bf74-d3762eb5c1dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "124/124 [==============================] - 34s 271ms/step - loss: 0.1712 - accuracy: 0.9370\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.1711609959602356, 0.9369685053825378]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "model.evaluate(valid_it, steps=valid_it.samples/valid_it.batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Conclusão"
      ],
      "metadata": {
        "id": "m3C2EFZdwkLr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Eu avaliei meu modelo nos dados de validação e observei resultados sólidos, o que me dá uma boa indicação de como o modelo provavelmente se comportará em dados não vistos, assumindo que os dados de validação são representativos do problema geral que estou tentando resolver. Aqui estão os detalhes e considerações baseados nos resultados fornecidos:\n",
        "\n",
        "1. **Perda (Loss)**: O valor da perda que eu observei é 0.1712, que é relativamente baixo. Isso indica que, em média, meu modelo tem um bom desempenho em minimizar a função de perda definida durante o treinamento. A função de perda quantifica o quanto as previsões do modelo desviam dos valores reais, portanto, quanto menor o valor, melhor.\n",
        "\n",
        "2. **Acurácia**: A acurácia de 93.70% é bastante alta, o que sugere que meu modelo está classificando corretamente uma grande proporção das amostras de validação. Este é um bom indicativo de desempenho, especialmente em tarefas de classificação onde a acurácia é uma métrica relevante e direta para avaliar a performance.\n",
        "\n",
        "3. **Análise de Overfitting e Underfitting**:\n",
        "   - **Overfitting**: Se a acurácia do treinamento for significativamente mais alta do que a acurácia de validação, isso pode indicar overfitting. Meu modelo seria então muito bom em prever dados de treinamento, mas não tão bom em generalizar para novos dados.\n",
        "   - **Underfitting**: Se ambas as acurácias, de treinamento e de validação, forem baixas, ou se a acurácia de validação for inesperadamente mais alta do que a de treinamento, isso pode indicar underfitting. Significaria que meu modelo é demasiado simples para capturar padrões complexos nos dados.\n",
        "\n",
        "4. **Consistência com Treinamento**: Comparando com os resultados anteriores de treinamento que compartilhei, onde a acurácia de validação alcançou até 95.11% em uma das épocas, a acurácia de 93.70% está um pouco abaixo, mas ainda assim é consistente. Isso pode ser devido a variações naturais nos diferentes subconjuntos de dados ou a pequenas diferenças na maneira como os dados de validação são processados ou selecionados.\n",
        "\n",
        "5. **Tempo por Etapa**: Cada etapa levou em média 271ms, o que é relativamente rápido e mostra que meu modelo é computacionalmente eficiente com os recursos atuais. Isso é importante se o modelo precisar ser implementado em um ambiente de produção onde o tempo de resposta é crítico.\n",
        "\n",
        "**Conclusão**:\n",
        "Parece que meu modelo está bem ajustado com uma boa performance na validação. No entanto, sempre há espaço para melhorias, especialmente se eu notar alguma tendência de overfitting ou se precisar de uma acurácia ainda maior. Eu poderia explorar ajustes adicionais nos hiperparâmetros, aumentar o conjunto de dados de treinamento, ou incorporar técnicas de regularização e augmentação de dados, conforme mencionado anteriormente."
      ],
      "metadata": {
        "id": "kewPcvRNwl7r"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1uIgRACzM4AN9XivY8Iaq6l6tqq1pIM5A",
      "authorship_tag": "ABX9TyNnyouGbOkmjSRLz9UJyhr2",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}